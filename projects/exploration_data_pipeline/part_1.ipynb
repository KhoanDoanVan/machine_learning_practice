{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13eeb196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ import t·∫•t c·∫£ th∆∞ vi·ªán c·∫ßn thi·∫øt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 1. IMPORT TH∆Ø VI·ªÜN C·∫¶N THI·∫æT\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Thi·∫øt l·∫≠p style cho visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# C·∫•u h√¨nh hi·ªÉn th·ªã pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "print(\"‚úì ƒê√£ import t·∫•t c·∫£ th∆∞ vi·ªán c·∫ßn thi·∫øt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a22730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ load d·ªØ li·ªáu: 768 h√†ng, 9 c·ªôt\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. CLASS ƒê·ªÇ QU·∫¢N L√ù QUY TR√åNH\n",
    "# ============================================================================\n",
    "\n",
    "class DataExplorationPipeline:\n",
    "    \"\"\"\n",
    "    Class ch√≠nh ƒë·ªÉ x·ª≠ l√Ω v√† kh√°m ph√° d·ªØ li·ªáu\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, data_path=None, df=None):\n",
    "        \"\"\"\n",
    "        Kh·ªüi t·∫°o pipeline\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data_path : str, optional\n",
    "            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file d·ªØ li·ªáu\n",
    "        df : DataFrame, optional\n",
    "            DataFrame c√≥ s·∫µn\n",
    "        \"\"\"\n",
    "\n",
    "        if df is not None:\n",
    "            self.df_original = df.copy()\n",
    "        elif data_path:\n",
    "            self.df_original = self._load_data(data_path)\n",
    "        else:\n",
    "            raise ValueError(\"C·∫ßn cung c·∫•p data_path ho·∫∑c df\")\n",
    "\n",
    "        self.df = self.df_original.copy()\n",
    "        self.numeric_cols = []\n",
    "        self.categorical_cols = []\n",
    "        self.datetime_cols = []\n",
    "        self.text_cols = []\n",
    "        self.report = {}\n",
    "\n",
    "        print(f\"‚úì ƒê√£ load d·ªØ li·ªáu: {self.df.shape[0]} h√†ng, {self.df.shape[1]} c·ªôt\")\n",
    "\n",
    "\n",
    "    def _load_data(self, path):\n",
    "        \"\"\"Load d·ªØ li·ªáu t·ª´ nhi·ªÅu ƒë·ªãnh d·∫°ng\"\"\"\n",
    "\n",
    "        if path.endswith('.csv'):\n",
    "            return pd.read_csv(path)\n",
    "        elif path.endswith('.xlsx') or path.endswith('.xls'):\n",
    "            return pd.read_excel(path)\n",
    "        elif path.endswith('.json'):\n",
    "            return pd.read_json(path)\n",
    "        elif path.endswith('.parquet'):\n",
    "            return pd.read_parquet(path)\n",
    "        else:\n",
    "            raise ValueError(\"ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£\")\n",
    "\n",
    "\n",
    "pipeline = DataExplorationPipeline(data_path='./data/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67d313",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1680882060.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef initial_assessment(self):\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# 3. PH√ÇN T√çCH T·ªîNG QUAN (INITIAL ASSESSMENT)\n",
    "# ========================================================================\n",
    "\n",
    "def initial_assessment(self):\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch t·ªïng quan ban ƒë·∫ßu c·ªßa t·∫≠p d·ªØ li·ªáu\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìã PH√ÇN T√çCH T·ªîNG QUAN D·ªÆ LI·ªÜU\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ======== 3.1. Xem m·∫´u d·ªØ li·ªáu ========\n",
    "    print(\"\\nüîç 5 H√ÄNG ƒê·∫¶U TI√äN:\")\n",
    "    print(self.df.head())\n",
    "\n",
    "    print(\"\\nüîç 5 H√ÄNG CU·ªêI C√ôNG:\")\n",
    "    print(self.df.tail())\n",
    "\n",
    "    # ======== 3.2. Th√¥ng tin c∆° b·∫£n ========\n",
    "    print(\"\\nüìä TH√îNG TIN C∆† B·∫¢N:\")\n",
    "    print(f\"  ‚Ä¢ S·ªë h√†ng: {self.df.shape[0]:,}\")\n",
    "    print(f\"  ‚Ä¢ S·ªë c·ªôt: {self.df.shape[1]}\")\n",
    "    print(f\"  ‚Ä¢ Dung l∆∞·ª£ng b·ªô nh·ªõ: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    # ======== 3.3. Ki·ªÉu d·ªØ li·ªáu ========\n",
    "    print(\"\\nüè∑Ô∏è  KI·ªÇU D·ªÆ LI·ªÜU:\")\n",
    "    dtype_counts = self.df.dtypes.value_counts()\n",
    "    for dtype, count in dtype_counts.items():\n",
    "        print(f\"  ‚Ä¢ {dtype}: {count} c·ªôt\")\n",
    "\n",
    "\n",
    "    print(\"\\nüìù CHI TI·∫æT C√ÅC C·ªòT:\")\n",
    "    info_df = pd.DataFrame({\n",
    "        'C·ªôt': self.df.columns,\n",
    "        'Ki·ªÉu d·ªØ li·ªáu': self.df.dtypes.values,\n",
    "        'Gi√° tr·ªã null': self.df.isnull().sum().values,\n",
    "        'T·ª∑ l·ªá null (%)': (self.df.isnull().sum() / len(self.df) * 100).values,\n",
    "        'Gi√° tr·ªã duy nh·∫•t': [self.df[col].nunique() for col in self.df.columns]\n",
    "    })\n",
    "    print(info_df.to_string(index=False))\n",
    "\n",
    "    # ======== 3.4. Ph√¢n lo·∫°i c·ªôt ========\n",
    "    self._classify_columns()\n",
    "\n",
    "    print(f\"\\nüî¢ C√ÅC C·ªòT S·ªê ({len(self.numeric_cols)}):\")\n",
    "    print(f\"  {', '.join(self.numeric_cols)}\")\n",
    "\n",
    "    print(f\"\\nüì¶ C√ÅC C·ªòT PH√ÇN LO·∫†I ({len(self.categorical_cols)}):\")\n",
    "    print(f\"  {', '.join(self.categorical_cols)}\")\n",
    "\n",
    "    if self.datetime_cols:\n",
    "        print(f\"\\nüìÖ C√ÅC C·ªòT TH·ªúI GIAN ({len(self.datetime_cols)}):\")\n",
    "        print(f\"  {', '.join(self.datetime_cols)}\")\n",
    "\n",
    "\n",
    "    # ======== 3.5. D·ªØ li·ªáu tr√πng l·∫∑p ========\n",
    "    duplicates = self.df.duplicated().sum()\n",
    "    print(f\"\\nüîÑ D·ªÆ LI·ªÜU TR√ôNG L·∫∂P:\")\n",
    "    print(f\"  ‚Ä¢ S·ªë h√†ng tr√πng: {duplicates} ({duplicates/len(self.df)*100:.2f}%)\")\n",
    "\n",
    "\n",
    "    # L∆∞u report\n",
    "    self.report['initial_assessment'] = {\n",
    "        'shape': self.df.shape,\n",
    "        'memory_mb': self.df.memory_usage(deep=True).sum() / 1024**2,\n",
    "        'duplicates': duplicates,\n",
    "        'column_types': {\n",
    "            'numeric': len(self.numeric_cols),\n",
    "            'categorical': len(self.categorical_cols),\n",
    "            'datetime': len(self.datetime_cols)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return info_df\n",
    "\n",
    "\n",
    "\n",
    "def _classify_columns(self):\n",
    "    \"\"\"Ph√¢n lo·∫°i c√°c c·ªôt theo ki·ªÉu d·ªØ li·ªáu\"\"\"\n",
    "\n",
    "    for col in self.df.columns:\n",
    "\n",
    "        # C·ªôt s·ªë\n",
    "        if pd.api.types.is_numeric_dtype(self.df[col]):\n",
    "            self.numeric_cols.append(col)\n",
    "\n",
    "        # C·ªôt datetime\n",
    "        elif pd.api.types.is_datetime64_any_dtype(self.df[col]):\n",
    "            self.datetime_cols.append(col)\n",
    "\n",
    "        # C·ªôt ph√¢n lo·∫°i\n",
    "        elif pd.api.types.is_categorical_dtype(self.df[col]) or pd.api.types.is_object_dtype(self.df[col]):\n",
    "            # Ki·ªÉm tra xem c√≥ ph·∫£i text d√†i kh√¥ng\n",
    "            if self.df[col].dtype == 'object':\n",
    "                avg_length = self.df[col].dropna().astype(str).str.len().mean()\n",
    "                if avg_length > 50:  # Text d√†i\n",
    "                    self.text_cols.append(col)\n",
    "                else:\n",
    "                    self.categorical_cols.append(col)\n",
    "            else:\n",
    "               self.categorical_cols.append(col)\n",
    " \n",
    "\n",
    "info_df = pipeline.initial_assessment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e158d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 4. TH·ªêNG K√ä M√î T√É (DESCRIPTIVE STATISTICS)\n",
    "# ========================================================================\n",
    "\n",
    "def description_statistics(self):\n",
    "    \"\"\"\n",
    "    Th·ªëng k√™ m√¥ t·∫£ chi ti·∫øt\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà TH·ªêNG K√ä M√î T·∫¢ CHI TI·∫æT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ======== 4.1. Th·ªëng k√™ cho bi·∫øn s·ªë ========\n",
    "    if self.numeric_cols:\n",
    "        print(\"\\nüî¢ BI·∫æN S·ªê:\")\n",
    "        desc_numeric = self.df[self.numeric_cols].describe(\n",
    "            percentiles=[.01, .05, .25, .5, .75, .95, .99]\n",
    "        ).T\n",
    "\n",
    "        # Th√™m th√¥ng tin b·ªï sung\n",
    "        desc_numeric['missing'] = self.df[self.numeric_cols].isnull().sum()\n",
    "        desc_numeric['missing_%'] = (desc_numeric['missing'] / len(self.df) * 100)\n",
    "        desc_numeric['skewness'] = self.df[self.numeric_cols].skew()\n",
    "        desc_numeric['kurtosis'] = self.df[self.numeric_cols].kurtosis()\n",
    "        \n",
    "        print(desc_numeric)\n",
    "\n",
    "\n",
    "    # ======== 4.2. Th·ªëng k√™ cho bi·∫øn ph√¢n lo·∫°i ========\n",
    "    if self.categorical_cols:\n",
    "        print(\"\\nüì¶ BI·∫æN PH√ÇN LO·∫†I:\")\n",
    "        for col in self.categorical_cols[:10]:  # Hi·ªÉn th·ªã t·ªëi ƒëa 10 c·ªôt\n",
    "            print(f\"\\n  ‚Üí {col}:\")\n",
    "            value_counts = self.df[col].value_counts()\n",
    "            missing = self.df[col].isnull().sum()\n",
    "\n",
    "            print(f\"     ‚Ä¢ S·ªë gi√° tr·ªã duy nh·∫•t: {self.df[col].nunique()}\")\n",
    "            print(f\"     ‚Ä¢ Gi√° tr·ªã thi·∫øu: {missing} ({missing/len(self.df)*100:.2f}%)\")\n",
    "            print(f\"     ‚Ä¢ Top 5 gi√° tr·ªã:\")\n",
    "            for val, count in value_counts.head().items():\n",
    "                print(f\"       - {val}: {count} ({count/len(self.df)*100:.2f}%)\")\n",
    "\n",
    "    return desc_numeric if self.numeric_cols else None\n",
    "\n",
    "\n",
    "pipeline.descriptive_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0724779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 5. PH√ÇN T√çCH GI√Å TR·ªä B·ªä THI·∫æU (MISSING VALUES ANALYSIS)\n",
    "# ========================================================================\n",
    "\n",
    "def analyze_missing_values(self, plot=True):\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch chi ti·∫øt gi√° tr·ªã b·ªã thi·∫øu\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    plot : bool\n",
    "        C√≥ v·∫Ω bi·ªÉu ƒë·ªì hay kh√¥ng\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üï≥Ô∏è  PH√ÇN T√çCH GI√Å TR·ªä B·ªä THI·∫æU\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # T√≠nh to√°n missing values\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Column': self.df.columns,\n",
    "        'Missing_Count': self.df.isnull().sum(),\n",
    "        'Missing_Percentage': (self.df.isnull().sum() / len(self.df) * 100)\n",
    "    })\n",
    "    missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values(\n",
    "        'Missing_Percentage', ascending=False\n",
    "    )\n",
    "\n",
    "    if len(missing_data) == 0:\n",
    "        print(\"‚úì Kh√¥ng c√≥ gi√° tr·ªã b·ªã thi·∫øu trong t·∫≠p d·ªØ li·ªáu!\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nüìä T·ªïng quan:\")\n",
    "    print(f\"  ‚Ä¢ S·ªë c·ªôt c√≥ gi√° tr·ªã thi·∫øu: {len(missing_data)}/{len(self.df.columns)}\")\n",
    "    print(f\"  ‚Ä¢ T·ªïng s·ªë gi√° tr·ªã thi·∫øu: {missing_data['Missing_Count'].sum():,}\")\n",
    "    print(f\"  ‚Ä¢ T·ª∑ l·ªá d·ªØ li·ªáu thi·∫øu: {(missing_data['Missing_Count'].sum() / (len(self.df) * len(self.df.columns)) * 100):.2f}%\")\n",
    "    \n",
    "    print(\"\\nüìã Chi ti·∫øt c√°c c·ªôt:\")\n",
    "    print(missing_data.to_string(index=False))\n",
    "\n",
    "    # Ph√¢n lo·∫°i m·ª©c ƒë·ªô thi·∫øu\n",
    "    severe = missing_data[missing_data['Missing_Percentage'] > 50]\n",
    "    moderate = missing_data[(missing_data['Missing_Percentage'] > 20) & \n",
    "                               (missing_data['Missing_Percentage'] <= 50)]\n",
    "    mild = missing_data[missing_data['Missing_Percentage'] <= 20]\n",
    "\n",
    "    print(f\"\\nüö® Ph√¢n lo·∫°i m·ª©c ƒë·ªô:\")\n",
    "    print(f\"  ‚Ä¢ Nghi√™m tr·ªçng (>50%): {len(severe)} c·ªôt\")\n",
    "    print(f\"  ‚Ä¢ Trung b√¨nh (20-50%): {len(moderate)} c·ªôt\")\n",
    "    print(f\"  ‚Ä¢ Nh·∫π (<20%): {len(mild)} c·ªôt\")\n",
    "\n",
    "    # Visualization\n",
    "    if plot and len(missing_data) > 0:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "        # Bar plot\n",
    "        missing_data.head(15).plot(\n",
    "            x='Column', y='Missing_Percentage', kind='barh', \n",
    "            ax=axes[0], color='coral'\n",
    "        )\n",
    "        axes[0].set_title('Top 15 C·ªôt C√≥ Nhi·ªÅu Gi√° Tr·ªã Thi·∫øu Nh·∫•t', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xlabel('T·ª∑ l·ªá thi·∫øu (%)')\n",
    "        axes[0].set_ylabel('')\n",
    "        \n",
    "        # Heatmap c·ªßa missing pattern\n",
    "        missing_cols = missing_data.head(15)['Column'].tolist()\n",
    "        if len(missing_cols) > 0:\n",
    "            sns.heatmap(\n",
    "                self.df[missing_cols].isnull(), \n",
    "                cbar=False, \n",
    "                yticklabels=False,\n",
    "                cmap='viridis',\n",
    "                ax=axes[1]\n",
    "            )\n",
    "            axes[1].set_title('Pattern c·ªßa Gi√° Tr·ªã Thi·∫øu', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    self.report['missing_values'] = missing_data.to_dict('records')\n",
    "    return missing_data\n",
    "\n",
    "\n",
    "pipeline.analyze_missing_values(plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97748b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 6. TR·ª∞C QUAN H√ìA PH√ÇN PH·ªêI (DISTRIBUTION VISUALIZATION)\n",
    "# ========================================================================\n",
    "\n",
    "def visualize_distributions(self, max_cols=10):\n",
    "    \"\"\"\n",
    "    Tr·ª±c quan h√≥a ph√¢n ph·ªëi c·ªßa c√°c bi·∫øn\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_cols : int\n",
    "        S·ªë l∆∞·ª£ng c·ªôt t·ªëi ƒëa ƒë·ªÉ hi·ªÉn th·ªã\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä TR·ª∞C QUAN H√ìA PH√ÇN PH·ªêI\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ======== 6.1. Bi·∫øn s·ªë ========\n",
    "    if self.numeric_cols:\n",
    "        print(\"\\nüî¢ Ph√¢n ph·ªëi bi·∫øn s·ªë:\")\n",
    "\n",
    "        cols_to_plot = self.numeric_cols[:max_cols]\n",
    "        n_cols = min(3, len(cols_to_plot))\n",
    "        n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "        axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]\n",
    "\n",
    "        for idx, col in enumerate(cols_to_plot):\n",
    "            data = self.df[col].dropna()\n",
    "\n",
    "            # Histogram + KDE\n",
    "            axes[idx].hist(data, bins=50, alpha=0.6, color='skyblue', edgecolor='black', density=True)\n",
    "\n",
    "            # KDE\n",
    "            if len(data) > 1:\n",
    "                data.plot(kind='kde', ax=axes[idx], color='red', linewidth=2)\n",
    "\n",
    "            axes[idx].set_title(f'{col}\\n(Skew: {data.skew():.2f}, Kurt: {data.kurtosis():.2f})', fontsize=10)\n",
    "            axes[idx].set_xlabel('')\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "        # ·∫®n c√°c subplot th·ª´a\n",
    "        for idx in range(len(cols_to_plot), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    # ======== 6.2. Bi·∫øn ph√¢n lo·∫°i ========\n",
    "    if self.categorical_cols:\n",
    "        print(\"\\nüì¶ Ph√¢n ph·ªëi bi·∫øn ph√¢n lo·∫°i:\")\n",
    "\n",
    "        cols_to_plot = [col for col in self.categorical_cols[:max_cols] \n",
    "                           if self.df[col].nunique() <= 20]\n",
    "\n",
    "        if cols_to_plot:\n",
    "            n_cols = min(3, len(cols_to_plot))\n",
    "            n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols\n",
    "\n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "            axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]\n",
    "\n",
    "            for idx, col in enumerate(cols_to_plot):\n",
    "                value_counts = self.df[col].value_counts().head(10)\n",
    "\n",
    "                axes[idx].barh(range(len(value_counts)), value_counts.values, color='teal')\n",
    "                axes[idx].set_yticks(range(len(value_counts)))\n",
    "                axes[idx].set_yticklabels(value_counts.index)\n",
    "                axes[idx].set_title(f'{col} (Top 10)', fontsize=10)\n",
    "                axes[idx].set_xlabel('S·ªë l∆∞·ª£ng')\n",
    "                axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        for idx in range(len(cols_to_plot), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "pipeline.visualize_distributions(max_cols=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. KH·ªûI T·∫†O V√Ä S·ª¨ D·ª§NG\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:\n",
    "\n",
    "# B∆∞·ªõc 1: Load d·ªØ li·ªáu\n",
    "pipeline = DataExplorationPipeline(data_path='your_data.csv')\n",
    "# Ho·∫∑c: pipeline = DataExplorationPipeline(df=your_dataframe)\n",
    "\n",
    "# B∆∞·ªõc 2: Ch·∫°y ph√¢n t√≠ch ban ƒë·∫ßu\n",
    "pipeline.initial_assessment()\n",
    "\n",
    "# B∆∞·ªõc 3: Th·ªëng k√™ m√¥ t·∫£\n",
    "pipeline.descriptive_statistics()\n",
    "\n",
    "# B∆∞·ªõc 4: Ph√¢n t√≠ch missing values\n",
    "pipeline.analyze_missing_values(plot=True)\n",
    "\n",
    "# B∆∞·ªõc 5: Visualize ph√¢n ph·ªëi\n",
    "pipeline.visualize_distributions(max_cols=12)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√É HO√ÄN TH√ÄNH PH·∫¶N 1: SETUP & EDA C∆† B·∫¢N\")\n",
    "print(\"üìå Ti·∫øp theo: Ch·∫°y Part 2 ƒë·ªÉ x·ª≠ l√Ω Data Cleaning & Preprocessing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
